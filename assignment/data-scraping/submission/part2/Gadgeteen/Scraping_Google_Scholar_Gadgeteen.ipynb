{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64afbe5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892409c0d3ac4c88a7f2f00c99b53f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import pymongo\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Define the MongoDB connection parameters\n",
    "mongo_uri = \"<uri>\"\n",
    "db_name = 'fc'\n",
    "collection_name = 'publications'\n",
    "\n",
    "# Create a new MongoDB client\n",
    "client = pymongo.MongoClient(mongo_uri)\n",
    "\n",
    "# Select the database\n",
    "db = client[db_name]\n",
    "\n",
    "# Select the collection\n",
    "collection = db[collection_name]\n",
    "\n",
    "url = 'https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=Faculty+of+Computing%2C+Universiti+Teknologi+Malaysia'\n",
    "\n",
    "scholar_list = []\n",
    "astart = 0\n",
    "#documents = []\n",
    "\n",
    "# Set up the Selenium driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Get the page source and parse it using Beautiful Soup\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find all the scholars, their affiliations and emails on the page\n",
    "    scholars = soup.find_all('h3', class_='gs_ai_name')\n",
    "    affs = soup.find_all('div', class_='gs_ai_aff')\n",
    "    emails = soup.find_all('div', class_='gs_ai_eml')\n",
    "\n",
    "    for scholar, aff, eml in zip(scholars, affs, emails):\n",
    "        # ignore scholars from Universiti Teknologi Mara (UiTM)\n",
    "        if not (re.search('MARA', aff.text, re.IGNORECASE) or re.search('uitm', eml.text, re.IGNORECASE)):\n",
    "            # add UTM FC scholars to the list\n",
    "            scholar_list.append(f\"https://scholar.google.com{scholar.find('a')['href']}\")\n",
    "\n",
    "    # get next page link from the next page button if it is present\n",
    "    if soup.select_one(\".gsc_pgn button.gs_btnPR\").get('onclick'):\n",
    "        after_author = re.search(r\"after_author\\\\x3d(.*)\\\\x26\", str(soup.select_one(\".gsc_pgn button.gs_btnPR\").get('onclick'))).group(1)\n",
    "        astart += 10\n",
    "        url = f'{url}&after_author={after_author}&astart={astart}'\n",
    "    else:\n",
    "        break\n",
    "\n",
    "with tqdm(total=len(scholar_list)) as pbar:  #progress bar\n",
    "    for scholar_url in scholar_list:\n",
    "\n",
    "        driver.get(scholar_url)\n",
    "\n",
    "        # click show more button in the profile page\n",
    "        for _ in range(0,3):\n",
    "            try:\n",
    "                #Wait up to 10s until the element is loaded on the page\n",
    "                element = WebDriverWait(driver, 5).until(\n",
    "                    #Locate element by id\n",
    "                    EC.presence_of_element_located((By.ID, 'gsc_bpf'))\n",
    "                )\n",
    "            finally:\n",
    "                element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Get the page source and parse it using Beautiful Soup\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # get the links for all articles on the page of the scholar\n",
    "        links = soup.find_all('a', class_='gsc_a_at')\n",
    "        links_list = []\n",
    "        for link in links:\n",
    "            links_list.append(f'https://scholar.google.com{link[\"href\"]}')\n",
    "\n",
    "        # loop through all article links of the scholar\n",
    "        for url in links_list:\n",
    "\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the page to load\n",
    "            driver.implicitly_wait(10)\n",
    "\n",
    "            # Get the page source and parse it using Beautiful Soup\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            result = soup.find('div', id='gsc_vcpb')\n",
    "\n",
    "            # format the data in dictionary format\n",
    "            document = {}\n",
    "            if result.find('a', class_='gsc_oci_title_link'):\n",
    "                document['Title'] = result.find('a', class_='gsc_oci_title_link').text\n",
    "                document['Link'] = result.find('a', class_='gsc_oci_title_link')['href']\n",
    "            else:\n",
    "                document['Title'] = result.find('div', id='gsc_oci_title').text\n",
    "            \n",
    "            for field, value in zip(result.find_all('div', class_='gsc_oci_field'), result.find_all('div', class_='gsc_oci_value')):\n",
    "                if field.text == 'Scholar articles':\n",
    "                    break\n",
    "                elif field.text == 'Total citations':\n",
    "                    document[field.text] = int(re.search(r'\\d+', value.find('a').text).group())\n",
    "                else:\n",
    "                    document[field.text] = value.text\n",
    "                \n",
    "            #documents.append(document)\n",
    "\n",
    "            # insert the document into MongoDB database\n",
    "            collection.insert_one(document)\n",
    "\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # update progress bar after each scholar iteration\n",
    "        pbar.update(1)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
