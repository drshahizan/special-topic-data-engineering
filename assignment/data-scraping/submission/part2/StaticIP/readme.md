# Assignment Part 2: Web Scraping Text Content

- [jupyter notebook](https://github.com/drshahizan/special-topic-data-engineering/blob/main/assignment/data-scraping/submission/part2/StaticIP/Google%20Scholar%20Scarping.ipynb)
- [csv output file](https://github.com/drshahizan/special-topic-data-engineering/blob/main/assignment/data-scraping/submission/part2/StaticIP/result.csv)
- [data scraping report](https://github.com/drshahizan/special-topic-data-engineering/blob/main/assignment/data-scraping/submission/part2/StaticIP/Report.md)

<table>
  <tr>
   <th>Group members</th>
   <th>Matric. No</th>
  </tr>
  <tr>
   <td>Chloe Racquelmae Kennedy</td>
   <td>A20EC0026</td>
  </tr>
  <tr>
   <td>Kong Jia Rou</td>
   <td>A20EC0198</td>
  </tr>
  <tr>
   <td>Lee Cai Xuan</td>
   <td>A20EC0062</td>
  </tr>
  <tr>
   <td>Singthai Srisoi</td>
   <td>A20EC0147</td>
  </tr>
</table>

Web scraping publication has become important for research and analysis. It allows researchers to gather and analyze large amounts of data efficiently. One valuable source for publication content is Google Scholar, a comprehensive search engine that indexes academic papers, theses, books and other sources.

In this assignment, we explored the process of web scraping publication content from Google Scholar and discussed the benefits of using libraries such as Beautiful Soup, Scrapy and Selenium. Besides, web scraping publication content also store it in database like MongoDB opens up a world of possibilities for research and analysis.






